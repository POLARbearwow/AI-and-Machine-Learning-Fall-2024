1. 最开始一直出现y_pred几乎为零 怀疑sigmoid导致梯度消失 换成了RELU
2. RELU还是出现类似情况，更换了初始化权重的方法 有所好转（起码不为零了）
3. 后来又变为零，losses竟然看着还能正常下降
4. 重新换成了更多层感知机，由两三层变成五六层，可以拟合一部分了，只是sgd可以 mbgd依然是零
5. He初始化相较于Xavier更不稳定 导致Nan？why
6. 添加了很多很多层 有时有用 大部分时候没用
7. 层数不能太多 否则全为零了 | epoch太大也很容易造成过拟合