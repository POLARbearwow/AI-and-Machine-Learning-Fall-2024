1. 最开始一直出现y_pred几乎为零 怀疑sigmoid导致梯度消失 换成了RELU
2. RELU还是出现类似情况，更换了初始化权重的方法 有所好转（起码不为零了）
3. 后来又变为零，losses竟然看着还能正常下降
4. 重新换成了更多层感知机，由两三层变成五六层，可以拟合一部分了，只是sgd可以 mbgd依然是零
5. He初始化相较于Xavier更不稳定 导致Nan？why
6. 添加了很多很多层 有时有用 大部分时候没用
7. 层数不能太多 否则全为零了 | epoch太大也很容易造成过拟合 | lr只要过大就会出现Nan
8. 更换成了leaky relu和权重初始化后 只是调整了一下lr以及mlp就可以看出效果（层数不能太多也不能太少 lr不能大）（后续验证一下时参数问题 还是激活函数和初始化问题）
9. 梯度消失 loss一直不变？s试了很多参数了 总是拟合不好